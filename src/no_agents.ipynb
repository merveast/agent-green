{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a91f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import config\n",
    "from datetime import datetime\n",
    "import ollama\n",
    "from codecarbon import EmissionsTracker\n",
    "from log_utils import read_log_messages, normalize_template, normalize_template_v1, normalize_template_v2, save_templates\n",
    "from ollama_utils import start_ollama_server, stop_ollama_server, start_ollama_server_log\n",
    "from evaluation import evaluate_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = config.LLM_CONFIG\n",
    "task = config.TASK_PROMPT\n",
    "sys_prompt_few_shot_single_log_parser = config.SYS_MSG_SINGLE_LOG_PARSER_FEW_SHOT\n",
    "sys_prompt_three_shot_single_log_parser = config.SYS_MSG_SINGLE_LOG_PARSER_THREE_SHOT\n",
    "sys_prompt_zero_shot_single_log_parser = config.SYS_MSG_SINGLE_LOG_PARSER_ZERO_SHOT\n",
    "\n",
    "LOG_DIR = config.LOG_DIR\n",
    "RESULT_DIR = config.RESULT_DIR\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "input_log_file = \"HDFS_200_sampled.log\"\n",
    "log_path = os.path.join(LOG_DIR, input_log_file)\n",
    "ground_truth_file_path = os.path.join(LOG_DIR, \"HDFS_200_sampled_log_structured.csv\")\n",
    "\n",
    "DESIGN = \"NA-zero\"\n",
    "\n",
    "model_name = llm_config[\"config_list\"][0][\"model\"]\n",
    "model = llm_config[\"config_list\"][0][\"model\"].replace(\":\", \"-\")\n",
    "temperature = llm_config[\"temperature\"] \n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "project_name = DESIGN.capitalize()\n",
    "exp_name = f\"{project_name}_{model}_{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ollama Query Function ---\n",
    "def ask_ollama(model, prompt):\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            options={'temperature': temperature}\n",
    "        )\n",
    "    except ollama.ResponseError as e:\n",
    "        print('Error:', e.error)\n",
    "        return None\n",
    "    return response.get('response', None)\n",
    "\n",
    "# --- Read Log Messages ---\n",
    "logs = read_log_messages(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f004283",
   "metadata": {},
   "source": [
    "With CodeCarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- With CodeCarbon ---\n",
    "def run_inference_with_emissions(logs, model_name, prompt_prefix, task, exp_name, result_dir):\n",
    "    parsed_templates = []\n",
    "    tracker = EmissionsTracker(project_name=exp_name, output_dir=result_dir, save_to_file=True)\n",
    "    tracker.start()\n",
    "    try:\n",
    "        for i, log_message in enumerate(logs):\n",
    "            #print(f\"Processing log {i+1}/{len(logs)}\")\n",
    "            prompt = prompt_prefix + task + log_message\n",
    "            response = ask_ollama(model_name, prompt)\n",
    "            if response is not None:\n",
    "                parsed_templates.append(response)\n",
    "                \n",
    "            else:\n",
    "                print(f\"[Warning] Skipped log {i} â€” no response or invalid format.\")\n",
    "    finally:\n",
    "        emissions = tracker.stop()\n",
    "    print(f\"Emissions: {emissions} kg CO2\")\n",
    "    return parsed_templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = start_ollama_server()\n",
    "time.sleep(5) # Give it some time to initialize\n",
    "parsed_templates = run_inference_with_emissions(logs, model_name, sys_prompt_zero_shot_single_log_parser, task, exp_name, RESULT_DIR)\n",
    "save_templates(parsed_templates, llm_config, DESIGN, RESULT_DIR)\n",
    "stop_ollama_server(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f38735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print Results ---\n",
    "#print(\"Templates:\", parsed_templates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc7bae",
   "metadata": {},
   "source": [
    "Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using normalize_template\n",
    "results = evaluate_and_save(normalize_template, parsed_templates, ground_truth_file_path, exp_name)\n",
    "# using normalize_template_v1\n",
    "results_v1 = evaluate_and_save(normalize_template_v1, parsed_templates, ground_truth_file_path, exp_name)\n",
    "# using normalize_template_v2\n",
    "results_v2 = evaluate_and_save(normalize_template_v2, parsed_templates, ground_truth_file_path, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
