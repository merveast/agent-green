{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a91f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import config\n",
    "from datetime import datetime\n",
    "import ollama\n",
    "from codecarbon import EmissionsTracker, OfflineEmissionsTracker\n",
    "from log_utils import read_log_messages, normalize_template, normalize_template_v1, normalize_template_v2, save_templates\n",
    "from debt_utils import get_code_snippets, get_td_ground_truth, save_td_labels, normalize_td_label\n",
    "from ollama_utils import start_ollama_server, stop_ollama_server, start_ollama_server_log\n",
    "from evaluation import evaluate_and_save_parsing, evaluate_and_save_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "llm_config = config.LLM_CONFIG\n",
    "\n",
    "DATA_DIR = config.DATA_DIR\n",
    "RESULT_DIR = config.RESULT_DIR\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    " \n",
    "TASK = (config.TASK).capitalize()\n",
    "DESIGN = (config.DESIGN).capitalize()\n",
    "project_name = f\"{TASK}_{DESIGN}\"\n",
    "model_name = llm_config[\"config_list\"][0][\"model\"]\n",
    "model = llm_config[\"config_list\"][0][\"model\"].replace(\":\", \"-\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "exp_name = f\"{project_name}_{model}_{timestamp}\"\n",
    "\n",
    "input_file = config.IN_FILE\n",
    "input_file_path = os.path.join(DATA_DIR, input_file)\n",
    "ground_truth_file = config.GT_FILE\n",
    "ground_truth_file_path = os.path.join(DATA_DIR, ground_truth_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ollama Query Function ---\n",
    "def ask_ollama(model, prompt, temperature=0):\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            options={'temperature': temperature},\n",
    "            think = False\n",
    "        )\n",
    "    except ollama.ResponseError as e:\n",
    "        print('Error:', e.error)\n",
    "        return None\n",
    "    return response.get('response', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e63c4",
   "metadata": {},
   "source": [
    "TD Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task-specific configuration ---\n",
    "task_prompt = config.TASK_PROMPT_TD_DETECTION\n",
    "sys_prompt_generator = config.SYS_MSG_TD_DETECTION_GENERATOR_FEW_SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_snippets = get_code_snippets(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TD Detection With CodeCarbon ---\n",
    "def run_inference_with_emissions_td_detection(code_snippets, model_name, sys_prompt, exp_name, result_dir):\n",
    "    td_results = []\n",
    "    tracker = OfflineEmissionsTracker(project_name=exp_name, output_dir=result_dir, country_iso_code=\"CAN\", save_to_file=True)\n",
    "    tracker.start()\n",
    "    try:\n",
    "        for i, code_snippet in enumerate(code_snippets):\n",
    "            #print(f\"Processing code_snippet {i+1}/{len(code_snippets)}\")\n",
    "            prompt = sys_prompt + code_snippet\n",
    "            response = ask_ollama(model_name, prompt)\n",
    "            if response is not None:\n",
    "                td_results.append(response)\n",
    "                \n",
    "            else:\n",
    "                print(f\"[Warning] Skipped code snippet {i} — no response or invalid format.\")\n",
    "    finally:\n",
    "        emissions = tracker.stop()\n",
    "    print(f\"Emissions: {emissions} kg CO2\")\n",
    "    return td_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = start_ollama_server()\n",
    "time.sleep(5) \n",
    "td_results = run_inference_with_emissions_td_detection(code_snippets, model_name, sys_prompt_generator, exp_name, RESULT_DIR)\n",
    "save_td_labels(td_results, llm_config, DESIGN, RESULT_DIR)\n",
    "stop_ollama_server(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "gt = get_td_ground_truth(ground_truth_file_path)\n",
    "# Evaluate and save results\n",
    "results = evaluate_and_save_td(normalize_td_label, gt, td_results, exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f004283",
   "metadata": {},
   "source": [
    "Log Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb17d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task-specific configuration ---\n",
    "task_prompt = config.TASK_PROMPT_LOG_PARSING\n",
    "sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_FEW_SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Read Input Data ---\n",
    "logs = read_log_messages(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log Parsing With CodeCarbon ---\n",
    "def run_inference_with_emissions_log_parsing(logs, model_name, prompt_prefix, task, exp_name, result_dir):\n",
    "    parsed_templates = []\n",
    "    tracker = EmissionsTracker(project_name=exp_name, output_dir=result_dir, save_to_file=True)\n",
    "    tracker.start()\n",
    "    try:\n",
    "        for i, log_message in enumerate(logs):\n",
    "            print(f\"Processing log {i+1}/{len(logs)}\")\n",
    "            prompt = prompt_prefix + task + log_message\n",
    "            response = ask_ollama(model_name, prompt)\n",
    "            if response is not None:\n",
    "                parsed_templates.append(response)\n",
    "                print(response)\n",
    "            else:\n",
    "                print(f\"[Warning] Skipped log {i} — no response or invalid format.\")\n",
    "    finally:\n",
    "        emissions = tracker.stop()\n",
    "    print(f\"Emissions: {emissions} kg CO2\")\n",
    "    return parsed_templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = start_ollama_server()\n",
    "time.sleep(5) # Give it some time to initialize\n",
    "parsed_templates = run_inference_with_emissions_log_parsing(logs, model_name, sys_prompt_generator, task_prompt, exp_name, RESULT_DIR)\n",
    "save_templates(parsed_templates, llm_config, DESIGN, RESULT_DIR)\n",
    "stop_ollama_server(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using normalize_template\n",
    "results = evaluate_and_save_parsing(normalize_template, parsed_templates, ground_truth_file_path, exp_name)\n",
    "# using normalize_template_v1\n",
    "results_v1 = evaluate_and_save_parsing(normalize_template_v1, parsed_templates, ground_truth_file_path, exp_name)\n",
    "# using normalize_template_v2\n",
    "results_v2 = evaluate_and_save_parsing(normalize_template_v2, parsed_templates, ground_truth_file_path, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
