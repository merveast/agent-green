{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a91f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import config\n",
    "from datetime import datetime\n",
    "from log_utils import read_log_messages, normalize_template, normalize_template_v1, normalize_template_v2, save_templates\n",
    "from ollama_utils import start_ollama_server, stop_ollama_server, start_ollama_server_log\n",
    "from autogen import AssistantAgent\n",
    "from codecarbon import EmissionsTracker, OfflineEmissionsTracker\n",
    "from evaluation import evaluate_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "llm_config = config.LLM_CONFIG\n",
    "\n",
    "DATA_DIR = config.DATA_DIR\n",
    "RESULT_DIR = config.RESULT_DIR\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    " \n",
    "TASK = (config.TASK).capitalize()\n",
    "DESIGN = (config.DESIGN).capitalize()\n",
    "project_name = f\"{TASK}_{DESIGN}\"\n",
    "model = llm_config[\"config_list\"][0][\"model\"].replace(\":\", \"-\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "exp_name = f\"{project_name}_{model}_{timestamp}\"\n",
    "\n",
    "input_file = config.IN_FILE\n",
    "input_file_path = os.path.join(DATA_DIR, input_file)\n",
    "ground_truth_file = config.GT_FILE\n",
    "ground_truth_file_path = os.path.join(DATA_DIR, ground_truth_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task-specific configuration ---\n",
    "task_prompt = None\n",
    "sys_prompt_generator = None\n",
    "\n",
    "# Normalize lowercase for comparisons\n",
    "task_lower = TASK.lower()\n",
    "design_lower = DESIGN.lower()\n",
    "\n",
    "if task_lower == \"log-parsing\":\n",
    "    task_prompt = config.TASK_PROMPT_LOG_PARSING\n",
    "    if design_lower == \"sa-few\":\n",
    "        sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_GENERATOR_FEW_SHOT\n",
    "    elif design_lower == \"sa-zero\":\n",
    "        sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_GENERATOR_ZERO_SHOT\n",
    "    elif design_lower == \"da-few\":\n",
    "        sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_GENERATOR_FEW_SHOT\n",
    "        sys_prompt_critic = config.SYS_MSG_SINGLE_LOG_PARSER_CRITIC_FEW_SHOT\n",
    "    elif design_lower == \"da-zero\":\n",
    "        sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_GENERATOR_ZERO_SHOT\n",
    "        sys_prompt_critic = config.SYS_MSG_SINGLE_LOG_PARSER_CRITIC_ZERO_SHOT\n",
    "    elif design_lower == \"ma-few\":\n",
    "        sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_GENERATOR_FEW_SHOT\n",
    "        sys_prompt_critic = config.SYS_MSG_SINGLE_LOG_PARSER_CRITIC_FEW_SHOT\n",
    "        sys_prompt_refiner = config.SYS_MSG_SINGLE_LOG_PARSER_REFINER_FEW_SHOT\n",
    "        sys_prompt_proxy = config.SYS_MSG_SINGLE_LOG_PARSER_PROXY_FEW_SHOT\n",
    "    elif design_lower == \"ma-zero\":\n",
    "        sys_prompt_generator = config.SYS_MSG_SINGLE_LOG_PARSER_GENERATOR_ZERO_SHOT\n",
    "        sys_prompt_critic = config.SYS_MSG_SINGLE_LOG_PARSER_CRITIC_ZERO_SHOT\n",
    "        sys_prompt_refiner = config.SYS_MSG_SINGLE_LOG_PARSER_REFINER_ZERO_SHOT\n",
    "        sys_prompt_proxy = config.SYS_MSG_SINGLE_LOG_PARSER_PROXY_ZERO_SHOT\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported DESIGN: {DESIGN}\")\n",
    "\n",
    "elif task_lower == \"td-detection\":\n",
    "    task_prompt = config.TASK_PROMPT_TD_DETECTION\n",
    "    if design_lower == \"ma-zero\":\n",
    "        sys_prompt_generator = config.SYS_MSG_TD_DETECTION_GENERATOR_ZERO_SHOT\n",
    "        sys_prompt_critic = config.SYS_MSG_TD_DETECTION_CRITIC_ZERO_SHOT\n",
    "        sys_prompt_refiner = config.SYS_MSG_TD_DETECTION_REFINER_ZERO_SHOT\n",
    "        sys_prompt_proxy = config.SYS_MSG_SINGLE_TD_DETECTION_PROXY_ZERO_SHOT\n",
    "\n",
    "elif task_lower == \"log-analysis\":\n",
    "    # Assign log-analysis-specific prompts here\n",
    "    pass\n",
    "\n",
    "elif task_lower == \"code-generation\":\n",
    "    # Assign code-generation-specific prompts here\n",
    "    pass\n",
    "\n",
    "elif task_lower == \"vul-detection\":\n",
    "    task_prompt = config.VULNERABILITY_TASK_PROMPT\n",
    "    if design_lower == \"ma-zero\":\n",
    "        \n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported TASK: {TASK}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log Reading ---\n",
    "logs = read_log_messages(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- With CodeCarbon Emissions Tracking for Log Parsing Task---\n",
    "def run_inference_with_emissions_log_parsing(logs, llm_config, sys_prompt_log_parser, task_prompt, exp_name, result_dir):\n",
    "    parsed_templates = []\n",
    "    tracker = OfflineEmissionsTracker(project_name=exp_name, output_dir=result_dir, country_iso_code=\"CAN\", save_to_file=True)\n",
    "    tracker.start()\n",
    "    try:\n",
    "        log_parser = create_agent(\n",
    "            agent_type=\"assistant\",\n",
    "            name=\"log_parser_agent\",\n",
    "            llm_config=llm_config,\n",
    "            sys_prompt=sys_prompt_log_parser,\n",
    "            description=\"Analyze the log message in order to determine the corresponding template.\"\n",
    "        )\n",
    "        for i, log_message in enumerate(logs):\n",
    "            content = task_prompt + log_message\n",
    "            res = log_parser.generate_reply(messages=[{\"content\": content, \"role\": \"user\"}])\n",
    "            if res is not None and \"content\" in res:\n",
    "                parsed_templates.append(res[\"content\"].strip())\n",
    "            else:\n",
    "                parsed_templates.append(\"NONE\")\n",
    "                print(f\"[Warning] Skipped log {i} â€” no response or invalid format.\")\n",
    "    finally:\n",
    "        emissions = tracker.stop()\n",
    "    print(f\"Emissions: {emissions} kg CO2\")\n",
    "    return parsed_templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "#proc = start_ollama_server()\n",
    "time.sleep(5)  # Give it some time to initialize\n",
    "parsed_templates = run_inference_with_emissions_log_parsing(logs, llm_config, sys_prompt_few_shot_single_log_parser, task_prompt, exp_name, RESULT_DIR)\n",
    "save_templates(parsed_templates, llm_config, DESIGN, RESULT_DIR)\n",
    "#stop_ollama_server(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Creation ---\n",
    "def create_single_log_parser_agent(llm_config, sys_prompt):\n",
    "    return AssistantAgent(\n",
    "        name=\"log_parser_agent\",\n",
    "        system_message=sys_prompt,\n",
    "        description=\"Analyze the log message in order to determine the corresponding template.\",\n",
    "        llm_config=llm_config,\n",
    "        human_input_mode=\"NEVER\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log Reading ---\n",
    "logs = read_log_messages(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print Results ---\n",
    "#print(\"Templates:\", parsed_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c334bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_and_save(normalize_template, parsed_templates, ground_truth_file_path, exp_name)\n",
    "results_v1 = evaluate_and_save(normalize_template_v1, parsed_templates, ground_truth_file_path, exp_name)\n",
    "results_v2 = evaluate_and_save(normalize_template_v2, parsed_templates, ground_truth_file_path, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7fdd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
